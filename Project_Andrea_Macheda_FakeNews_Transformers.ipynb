{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection de Fake News avec BERT et les Transformers\n",
    "\n",
    "Ce projet utilise le modèle de langage BERT et l'architecture Transformer pour créer un modèle de classification capable de distinguer les articles vrais des articles faux. Le dataset utilisé contient deux ensembles de données représentant respectivement les articles véridiques et les fake news. \n",
    "\n",
    "### Objectifs\n",
    "1. Prétraiter les données textuelles pour les adapter aux modèles basés sur des Transformers.\n",
    "2. Utiliser un modèle BERT pré-entraîné pour encoder les textes en vecteurs représentatifs.\n",
    "3. Entraîner un modèle de classification pour distinguer les articles en vraies et fausses nouvelles.\n",
    "4. Évaluer la performance du modèle à l'aide de métriques de classification standard.\n",
    "\n",
    "Dans ce notebook, nous allons procéder étape par étape pour réaliser cet objectif.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des bibliothèques nécessaires\n",
    "\n",
    "Cette cellule installe les bibliothèques `pandas`, `torch`, et `transformers` nécessaires pour le traitement du langage naturel avec le modèle BERT.\n",
    "\n",
    "#### Étapes :\n",
    "1. Installation de `pandas` pour la manipulation des données.\n",
    "2. Installation de `transformers` de Hugging Face pour utiliser des modèles de langage avancés.\n",
    "3. Installation de `torch` pour la prise en charge de PyTorch, essentiel pour les opérations de calcul du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-X-ueAdCYsdJ",
    "outputId": "2827b252-338b-4623-cbc9-79afcd47b96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0aNZZpmbOLA",
    "outputId": "7fc54fe4-9f97-442c-ea38-ebe1c7bd1ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from requests->transformers) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lTVq5UUbOlL",
    "outputId": "02e7700a-3bd4-4732-db68-911d0786a7a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deded\\documents\\inge3\\nlp\\project\\envfakenews\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qTwgQmaabK3V"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deded\\Documents\\Inge3\\NLP\\Project\\envFakeNews\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import transformers as transf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des bibliothèques et des données\n",
    "\n",
    "Dans cette cellule, nous chargeons deux jeux de données de nouvelles au format CSV, `Fake.csv` et `True.csv`, contenant respectivement des articles de fausses nouvelles et de vraies nouvelles. \n",
    "\n",
    "1. **Lecture des fichiers CSV** : \n",
    "   - Nous utilisons `pd.read_csv()` pour charger les fichiers dans deux DataFrames : `fake_news_df` et `real_news_df`.\n",
    "   \n",
    "2. **Ajout d'une colonne de label** :\n",
    "   - Une colonne `label` est ajoutée pour chaque dataset : `0` pour les fausses nouvelles, `1` pour les vraies nouvelles, ce qui facilitera la distinction entre les deux classes plus tard.\n",
    "   \n",
    "3. **Filtrage des articles courts** :\n",
    "   - Afin de simplifier le modèle, nous filtrons les articles dont le texte est inférieur à `60 mots`.\n",
    "   \n",
    "4. **Équilibrage des classes** :\n",
    "   - Pour éviter un biais de classe, on sélectionne un nombre égal d'articles dans chaque catégorie (classe minoritaire). Cette opération se fait en prenant l'échantillon `min_class_size` avec `random_state=42` pour garantir la reproductibilité.\n",
    "   \n",
    "5. **Fusion et mélange des données** :\n",
    "   - Les deux DataFrames sont fusionnés en un DataFrame `combined_news_df` et les lignes sont mélangées pour éviter tout biais de séquençage.\n",
    "   \n",
    "Enfin, nous affichons quelques lignes de données pour une première vérification visuelle du dataset combiné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkidQ1gZZMkv",
    "outputId": "6b0c1ecc-fb2f-4de6-b588-dd74e1c70c95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIZ WARREN CALLED OUT For Crazy Claim Steve Ba...</td>\n",
       "      <td>Liberals  internal struggle in one clip: .@and...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Dec 1, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No. 2 House Republican says healthcare bill de...</td>\n",
       "      <td>WASHINGTON (Reuters) - The No. 2 Republican in...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 23, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catalan government says 90 percent voted to le...</td>\n",
       "      <td>MADRID (Reuters) - The Catalan government said...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 1, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIND-BLOWING INTERACTIVE MAP Shows Where Musli...</td>\n",
       "      <td>This is a great visual to share with people wh...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Oct 29, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump to meet with Senate Republican leader Mc...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Republican preside...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 9, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LIZ WARREN CALLED OUT For Crazy Claim Steve Ba...   \n",
       "1  No. 2 House Republican says healthcare bill de...   \n",
       "2  Catalan government says 90 percent voted to le...   \n",
       "3  MIND-BLOWING INTERACTIVE MAP Shows Where Musli...   \n",
       "4  Trump to meet with Senate Republican leader Mc...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Liberals  internal struggle in one clip: .@and...     left-news   \n",
       "1  WASHINGTON (Reuters) - The No. 2 Republican in...  politicsNews   \n",
       "2  MADRID (Reuters) - The Catalan government said...     worldnews   \n",
       "3  This is a great visual to share with people wh...     left-news   \n",
       "4  WASHINGTON (Reuters) - U.S. Republican preside...  politicsNews   \n",
       "\n",
       "               date  label  \n",
       "0       Dec 1, 2016      0  \n",
       "1   March 23, 2017       1  \n",
       "2  October 1, 2017       1  \n",
       "3      Oct 29, 2015      0  \n",
       "4      May 9, 2016       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "fake_news_path = \"Fake.csv\"\n",
    "real_news_path = \"True.csv\"\n",
    "\n",
    "# Lire les deux fichiers\n",
    "fake_news_df = pd.read_csv(fake_news_path)\n",
    "real_news_df = pd.read_csv(real_news_path)\n",
    "\n",
    "# Ajouter une colonne \"label\" à chaque dataset\n",
    "fake_news_df['label'] = 0  # Faux articles\n",
    "real_news_df['label'] = 1  # Vrais articles\n",
    "\n",
    "# Filtrer les articles avec une longueur de texte inférieure à 50 mots\n",
    "max_words = 60\n",
    "fake_news_df = fake_news_df[fake_news_df['text'].apply(lambda x: len(x.split()) < max_words)]\n",
    "real_news_df = real_news_df[real_news_df['text'].apply(lambda x: len(x.split()) < max_words)]\n",
    "\n",
    "# Équilibrer les classes en sélectionnant un nombre égal d'articles\n",
    "min_class_size = min(len(fake_news_df), len(real_news_df))  # Nombre minimal entre les deux classes\n",
    "\n",
    "fake_news_df_balanced = fake_news_df.sample(n=min_class_size, random_state=42)\n",
    "real_news_df_balanced = real_news_df.sample(n=min_class_size, random_state=42)\n",
    "\n",
    "# Fusionner les deux datasets équilibrés\n",
    "combined_news_df = pd.concat([fake_news_df_balanced, real_news_df_balanced], ignore_index=True)\n",
    "\n",
    "# Mélanger les données pour éviter l'ordre initial\n",
    "combined_news_df = combined_news_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Afficher quelques lignes du dataset combiné pour vérifier\n",
    "combined_news_df.head(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution des Labels\n",
    "\n",
    "Cette cellule permet de vérifier que le dataset est bien équilibré. La méthode `value_counts()` est appliquée à la colonne `label` du DataFrame combiné, `combined_news_df`, pour compter le nombre de faux et de vrais articles. Le résultat confirme que chaque classe a un nombre égal d'échantillons, ce qui est crucial pour un apprentissage supervisé équilibré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "PlXR2wK2ZtoC",
    "outputId": "eb26a8bb-05ff-4c08-8e55-f6aac0a05b50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    679\n",
       "1    679\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts =combined_news_df['label'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du Modèle de Transformer et du Tokenizer\n",
    "\n",
    "Nous définissons ici le modèle de Transformer et son tokenizer. \n",
    "\n",
    "1. **Choix du modèle DistilBERT** : \n",
    "   - Nous choisissons `DistilBERT`, une version allégée de BERT, pour des raisons de performance tout en maintenant une qualité acceptable.\n",
    "   \n",
    "2. **Initialisation du Tokenizer et du Modèle** : \n",
    "   - `tokenizer_c.from_pretrained(weights_pretrained)` et `model_class.from_pretrained(weights_pretrained)` permettent de charger respectivement le tokenizer et le modèle préentraînés. Ces éléments facilitent la tokenisation des textes et la génération de représentations numériques des articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "m4wzbyQCbDyF"
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_c, weights_pretrained = (transf.DistilBertModel, transf.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_c.from_pretrained(weights_pretrained)\n",
    "model = model_class.from_pretrained(weights_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation des Textes\n",
    "\n",
    "Cette cellule applique le tokenizer aux textes des articles. \n",
    "\n",
    "1. **Tokenisation des articles** : \n",
    "   - La fonction `tokenizer.encode()` convertit chaque texte en une séquence d'IDs de tokens en ajoutant des `tokens spéciaux` qui indiquent les débuts et fins des séquences.\n",
    "   \n",
    "Le résultat est une série de listes d'IDs de tokens, qui représentent chaque article sous une forme compatible avec le modèle DistilBERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0ydMQnPbmVN",
    "outputId": "519abec0-af45-40ff-9533-4b89a0eec28c"
   },
   "outputs": [],
   "source": [
    "tokenized = combined_news_df['text'].apply((lambda x : tokenizer.encode(x, add_special_tokens= True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "84qujdqCb1v9",
    "outputId": "c74ae577-b08c-4656-ee0e-c8d035c58ade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 13350, 4722, 5998, 1999, 2028, 12528, 10...\n",
       "1       [101, 2899, 1006, 26665, 1007, 1011, 1996, 205...\n",
       "2       [101, 6921, 1006, 26665, 1007, 1011, 1996, 139...\n",
       "3       [101, 2023, 2003, 1037, 2307, 5107, 2000, 3745...\n",
       "4       [101, 2899, 1006, 26665, 1007, 1011, 1057, 101...\n",
       "                              ...                        \n",
       "1353    [101, 7211, 1006, 26665, 1007, 1011, 2822, 234...\n",
       "1354    [101, 1006, 26665, 1007, 1011, 10210, 2102, 19...\n",
       "1355    [101, 2899, 1006, 26665, 1007, 1011, 3951, 520...\n",
       "1356    [101, 27084, 4048, 1010, 3607, 1006, 26665, 10...\n",
       "1357    [101, 20312, 1006, 26665, 1007, 1011, 4977, 23...\n",
       "Name: text, Length: 1358, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la Longueur Maximale des Séquences\n",
    "\n",
    "Nous trouvons ici la longueur maximale des séquences tokenisées. \n",
    "\n",
    "1. **Calcul de `max_len`** : \n",
    "   - En parcourant chaque séquence tokenisée, nous obtenons la longueur maximale. \n",
    "   - Cette longueur est utile pour normaliser toutes les séquences à la même taille, en remplissant les séquences plus courtes avec des zéros.\n",
    "\n",
    "Cela garantit que toutes les séquences ont la même longueur, ce qui est une exigence pour le traitement par les modèles de Transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lyHW-0tb-Rj",
    "outputId": "733c3faf-bf6a-41d0-d3a3-c17c1a14c99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "  if len(i) > max_len:\n",
    "    max_len = len(i)\n",
    "\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplissage des Séquences (Padding)\n",
    "\n",
    "Dans cette cellule, nous appliquons le remplissage (padding) aux séquences de tokens.\n",
    "\n",
    "1. **Ajout de zéros** : \n",
    "   - Chaque séquence est remplie de zéros à la fin, jusqu'à atteindre `max_len`. \n",
    "   - Cela garantit que toutes les séquences ont la même longueur et permet un traitement efficace par le modèle.\n",
    "\n",
    "Nous utilisons `np.array()` pour convertir le résultat en un tableau NumPy, adapté pour les opérations par lots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pesaWLMpcAqa"
   },
   "outputs": [],
   "source": [
    "tokenized_zeroes = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9xaStzzcFvG",
    "outputId": "b1890f53-142b-40f5-a83d-89983564aeb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 233)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tokenized_zeroes).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du Masque d'Attention\n",
    "\n",
    "Nous créons ici le masque d’attention, qui indique les tokens réels et les tokens de remplissage.\n",
    "\n",
    "1. **Génération du masque** : \n",
    "   - `np.where(tokenized_zeroes != 0, 1, 0)` crée un masque où chaque token réel est marqué par `1` et chaque token de remplissage par `0`.\n",
    "   \n",
    "Le masque d’attention informe le modèle de ne pas prendre en compte les tokens de remplissage lors de la génération des embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVV5QmapcIcV",
    "outputId": "34e4ccbf-f30d-4daa-c61f-fc89958ece89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(tokenized_zeroes != 0, 1, 0)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpR0LIj_cMnR",
    "outputId": "0d5485be-0575-4007-86bc-798f17e25aaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 233)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion en Tenseurs PyTorch\n",
    "\n",
    "Cette cellule convertit les séquences et le masque d’attention en tenseurs PyTorch. \n",
    "\n",
    "1. **Conversion des tokens et du masque en tenseurs** : \n",
    "   - `torch.tensor()` transforme les tableaux NumPy en objets PyTorch, permettant ainsi leur passage au modèle pour le traitement. \n",
    "\n",
    "Les tenseurs `input_ids` et `attention_mask` sont ainsi prêts pour le modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oucLL1qWcNPb"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenized_zeroes)\n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ5r0XKTcQKT",
    "outputId": "5b4f07f6-e57f-4fb5-afd6-45e1df00c338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 13350,  4722,  ...,     0,     0,     0],\n",
       "        [  101,  2899,  1006,  ...,     0,     0,     0],\n",
       "        [  101,  6921,  1006,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2899,  1006,  ...,     0,     0,     0],\n",
       "        [  101, 27084,  4048,  ...,     0,     0,     0],\n",
       "        [  101, 20312,  1006,  ...,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des États Cachés du Modèle\n",
    "\n",
    "Dans cette cellule, nous faisons passer les tenseurs à travers le modèle pour extraire les états cachés.\n",
    "\n",
    "1. **Passage par le modèle DistilBERT** : \n",
    "   - Avec `torch.no_grad()`, nous désactivons la sauvegarde des gradients, économisant ainsi de la mémoire.\n",
    "   - `model(input_ids, attention_mask=attention_mask)` retourne les représentations de chaque token dans chaque séquence, soit le dernier état caché pour chaque token.\n",
    "\n",
    "Les états cachés obtenus servent de caractéristiques de haut niveau pour chaque article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WmC1-m7VcSeg"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  last_hidden_states = model(input_ids, attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection des Caractéristiques du CLS Token\n",
    "\n",
    "Nous extrayons ici les caractéristiques du token `[CLS]` pour chaque séquence. \n",
    "\n",
    "1. **Sélection du premier token** :\n",
    "   - Dans les modèles de Transformers, le token `[CLS]` (première position) contient une représentation de l’ensemble de la séquence, utile pour la classification.\n",
    "   - `features = last_hidden_states[0][:,0,:]` extrait ces caractéristiques pour chaque article.\n",
    "\n",
    "Ces caractéristiques seront utilisées comme vecteurs d’entrée pour la classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZLmhvogAcVHW"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "arAbemhPcXhn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1358, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des Labels\n",
    "\n",
    "\n",
    "Cette cellule extrait les labels associés aux articles dans `combined_news_df`. \n",
    "\n",
    "1. **Labeling des caractéristiques** : \n",
    "   - `labels = combined_news_df[\"label\"]` récupère les étiquettes `0` ou `1` indiquant si chaque article est faux ou vrai.\n",
    "   \n",
    "Ces labels seront utilisés pour entraîner et évaluer notre modèle de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UZuIrqBncZIa"
   },
   "outputs": [],
   "source": [
    "labels = combined_news_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division des Données en Enseignement et Test\n",
    "\n",
    "Nous divisons ici les données en ensembles d’apprentissage et de test.\n",
    "\n",
    "1. **Séparation aléatoire des ensembles** :\n",
    "   - `train_test_split(features, labels)` crée deux ensembles : un pour l’entraînement (`train_features`, `train_labels`) et un pour le test (`test_features`, `test_labels`). \n",
    "\n",
    "La séparation permet d’évaluer la performance du modèle sur des données non vues pendant l’entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vX6xRamkccmU"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Entraînement d'un Classifieur Logistique\n",
    "\n",
    "Dans cette cellule, nous entraînons un modèle de régression logistique sur les données d’entraînement.\n",
    "\n",
    "1. **Entraînement** :\n",
    "   - `lr_clf.fit(train_features, train_labels)` ajuste le modèle de régression logistique en utilisant les vecteurs de caractéristiques extraits du modèle DistilBERT.\n",
    "   \n",
    "Ce modèle de régression logistique servira de classificateur pour prédire si un article est vrai ou faux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation de Précision du Modèle\n",
    "\n",
    "Cette cellule évalue la précision du modèle de régression logistique sur l’ensemble de test.\n",
    "\n",
    "1. **Calcul de précision** :\n",
    "   - `lr_clf.score(test_features, test_labels)` mesure la précision du modèle sur les données de test.\n",
    "   \n",
    "La précision obtenue donne un aperçu de la capacité du modèle à généraliser sur de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970588235294118"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction sur un Nouvel Exemple\n",
    "\n",
    "Ici, nous testons notre pipeline complet sur un nouvel exemple.\n",
    "\n",
    "1. **Prétraitement et prédiction** :\n",
    "   - `tokenizer.encode()` et `padding` préparent le texte pour le modèle.\n",
    "   - Nous passons les données préparées par le modèle et obtenons `features` (le vecteur `[CLS]`).\n",
    "   - `lr_clf.predict(features)` retourne la prédiction et `lr_clf.predict_proba(features)` fournit les probabilités pour chaque classe.\n",
    "\n",
    "Ce test montre comment le modèle prédit la probabilité d'appartenance d’un nouvel article à la classe \"vrai\" ou \"faux\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= tokenizer.encode(\"jossua is beautifull\", add_special_tokens= True)\n",
    "tokenized_zeroes = np.array([text + [0]*(max_len - len(text))])\n",
    "input_ids = torch.tensor(tokenized_zeroes)\n",
    "attention_mask = torch.tensor(np.where(tokenized_zeroes != 0, 1, 0))\n",
    "with torch.no_grad():\n",
    "  last_hidden_states = model(input_ids, attention_mask = attention_mask)\n",
    "features = last_hidden_states[0][:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99258559e-01, 7.41440974e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "En conclusion, ce projet démontre l'efficacité du modèle DistilBERT pour la tâche de classification des fake news. Nous avons obtenu des résultats solides en utilisant les caractéristiques extraites par le modèle Transformer, qui a permis de transformer chaque article en un vecteur de haute dimension, facilement exploitable par un modèle de régression logistique pour la classification.\n",
    "\n",
    "En comparaison avec notre approche précédente utilisant des réseaux de type LSTM, les résultats obtenus avec DistilBERT sont sensiblement similaires en termes de précision et de capacité de généralisation. Cette observation est intéressante car elle suggère que, bien que les modèles de type Transformer comme DistilBERT soient réputés pour leurs performances exceptionnelles dans de nombreuses tâches NLP, les LSTM, une approche plus ancienne, peuvent offrir une performance comparable dans ce cas précis.\n",
    "\n",
    "Cela peut être dû à plusieurs facteurs, notamment le fait que notre tâche de classification est relativement simple et que la longueur des textes n'est pas très longue dans le cas voulu, ce qui ne justifie peut-être pas pleinement la puissance de DistilBERT. De plus, les LSTM sont capables de capter les relations temporelles et séquentielles dans les données, ce qui peut être avantageux dans des contextes où les structures de texte complexes sont essentielles.\n",
    "\n",
    "En résumé, bien que DistilBERT soit un modèle plus moderne et souvent plus performant pour des tâches de compréhension de texte complexes, les LSTM, lorsqu'ils sont bien entraînés, peuvent donner des résultats similaires pour des tâches comme la détection de fake news. Le choix du modèle peut donc être guidé par des contraintes pratiques telles que les ressources de calcul disponibles ou la taille des données à traiter.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "envFakeNews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
